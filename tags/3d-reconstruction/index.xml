<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>3D Reconstruction on Cayman</title>
    <link>https://example.com/tags/3d-reconstruction/</link>
    <description>Recent content in 3D Reconstruction on Cayman</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 18 May 2019 14:26:00 +0800</lastBuildDate>
    
	<atom:link href="https://example.com/tags/3d-reconstruction/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>双目立体视觉 with PatchMatch</title>
      <link>https://example.com/posts/%E5%8F%8C%E7%9B%AE%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89patchmatch/</link>
      <pubDate>Sat, 18 May 2019 14:26:00 +0800</pubDate>
      
      <guid>https://example.com/posts/%E5%8F%8C%E7%9B%AE%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89patchmatch/</guid>
      <description>Introduction 通过模仿人的两只眼睛如何估计深度，我们有了双目立体视觉系统。
一个双目立体视觉系统的结构如上图所示，$\rm O$ 和 $\rm O&amp;rsquo;$ 是两个相机的投影中心，$\rm B$ 是投影中心之间的距离，$f$ 是焦距，则物体 $\rm X$ 的深度 $\rm Z$ 可以通过它在左右相机图像中成像点横坐标 $x$ 和 $x&amp;rsquo;$ 之差，即视差，和 $\rm B$、$f$ 求得。视差和深度的转换关系并不那么一目了然，具体的推导可以参见这里。
在双目立体视觉系统中，$f$ 和 $\rm B$ 可以通过相机标定比较准确地求得，而求视差的问题可以转化为求 $ X$ 在另一幅图像中的对应点 $ X&amp;rsquo;$ 的问题，也就是本文的主角 —— 立体匹配。
可以看到上面求视差的过程有一个前提，$ X$ 和 $ X&amp;rsquo;$ 必须在图像的同一行上，这个我们可以通 Stereo Rectification 来达成。
Method 现在来明确一下立体匹配问题，输入是两幅经过 Stereo Rectification 的图像，输出是每个像素点的视差，任务是以一幅图像像素点为参考，在另一幅图像的同一行中搜索与之匹配的点。
一个最基本的方法是比较两个像素点的绝对值差异然后取值最小的点为匹配点，但是由于图像噪声和相邻像素点的近似性这个方法基本不可用。为了增加它的鲁棒性，可以用一个窗口内的像素去做对比而非单个像素，这时用窗口内所有像素的绝对值差之和或者绝对值差的平方和等方法来度量两个窗口的匹配代价，选取代价的作为匹配点，这就是最原始的立体匹配算法了。
Experiment 立体匹配算法经过多年发展有了很多不同的实现，但其基本的套路始终是寻找合适的代价函数计算匹配点之间的匹配代价以及如何减小匹配代价这两个方面。这里以 OpenCV 中的各种算法为例，来展示一下立体匹配的效果。截止 OpenCV 4.1，其中实现了8种立体匹配算法。以下结果为视差图，视差图的每个像素点的灰度值即代表该点的视差，为了增强图像对比度，这里对视差乘了3再做显示。
以上测试的输入为两张 427x370 分辨率的左右左右图像，CPU 和 GPU 环境分别为 i5-7400@3.00GHz x 4 和 GTX 1660 Ti。可以看到 OpenCV 的算法运行时间均在毫秒级别，在 CPU下可以选择 StereoSGBM，GPU下可以选择 StereoConstantSpaceBP 以达到不错的效果和运行时间的平衡。测试的源码及数据在这里可以找到。</description>
    </item>
    
  </channel>
</rss>