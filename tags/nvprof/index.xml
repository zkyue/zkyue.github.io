<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>nvprof on Cayman</title>
    <link>https://example.com/tags/nvprof/</link>
    <description>Recent content in nvprof on Cayman</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Jun 2019 14:26:00 +0800</lastBuildDate>
    
	<atom:link href="https://example.com/tags/nvprof/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>使用 nvprof 来检测 CUDA 程序运行效率</title>
      <link>https://example.com/posts/%E4%BD%BF%E7%94%A8nvprof%E6%9D%A5%E6%A3%80%E6%B5%8Bcuda%E7%A8%8B%E5%BA%8F%E8%BF%90%E8%A1%8C%E6%95%88%E7%8E%87/</link>
      <pubDate>Mon, 03 Jun 2019 14:26:00 +0800</pubDate>
      
      <guid>https://example.com/posts/%E4%BD%BF%E7%94%A8nvprof%E6%9D%A5%E6%A3%80%E6%B5%8Bcuda%E7%A8%8B%E5%BA%8F%E8%BF%90%E8%A1%8C%E6%95%88%E7%8E%87/</guid>
      <description>nvprof 是 CUDA Toolkit 自带的 CUDA 程序运行效率分析工具。它可以生成 kernel 函数和 CUDA API 运行时间报表，肥肠好用！有了它你再也不用调系统的时间函数把代码搞得乱七八糟的了。下面请看示例。
#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;curand_kernel.h&amp;gt;__global__ void hello() { printf(&amp;#34;Hello CUDA!\n&amp;#34;); } int main() { cudaFree(0); hello&amp;lt;&amp;lt;&amp;lt;1,10&amp;gt;&amp;gt;&amp;gt;(); cudaDeviceReset(); return 0; }  我们编译然后使用 nvprof 运行可以得到如下结果：
nvprof 会别类分门统计出一个详尽的结果，这里面需要注意的点有：
 nvprof 在 Nvidia Driver 418 以后的版本中使用受到限制，报错为&amp;rdquo;Waining：The user does not have permission to profile on the target device.&amp;ldquo;，我按照官网的操作不 work，最后在知乎找到的解决方案，备份如下：   CUDA 启动和释放运行环境都需要时间，这个会算在程序调用的 CUDA API 的第一个和最后一个头上，如果你调用的第一个函数是 cudaMalloc() 你可能会觉得内存分配怎么会这么慢！我这里用 cudaFree(0)和 cudaDeviceReset() 来为这两个时间背锅,可以看到它们的耗时都在几十上百毫秒的级别。 如果你需要在 kernel 函数中打印输出，直接调用 kernel 函数是没有效果的，可以在程序末尾调用cudaDeviceReset()或cudaDeviceSynchronize()来达到设备同步。  </description>
    </item>
    
  </channel>
</rss>